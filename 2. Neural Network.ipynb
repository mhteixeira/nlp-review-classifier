{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>REVIEW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRUTHFULPOSITIVE</td>\n",
       "      <td>The sheraton was a wonderful hotel! When me an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRUTHFULPOSITIVE</td>\n",
       "      <td>We stayed at the Omni between Christmas and Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DECEPTIVENEGATIVE</td>\n",
       "      <td>I was REALLY looking forward to a nice relaxin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRUTHFULNEGATIVE</td>\n",
       "      <td>First let me say, I try not to be too critical...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DECEPTIVENEGATIVE</td>\n",
       "      <td>The Ambassador East Hotel is a terrible place ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>TRUTHFULNEGATIVE</td>\n",
       "      <td>I stayed here for 5 nights last summer. I book...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>TRUTHFULPOSITIVE</td>\n",
       "      <td>Stayed here for 3 nights for a Bridgestone/Fir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>TRUTHFULNEGATIVE</td>\n",
       "      <td>I am staying here now and actually am compelle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>TRUTHFULNEGATIVE</td>\n",
       "      <td>We stayed at this hotel with our two teenage d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>DECEPTIVEPOSITIVE</td>\n",
       "      <td>The rooms were beautiful! The staff was friend...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  LABEL                                             REVIEW\n",
       "0      TRUTHFULPOSITIVE  The sheraton was a wonderful hotel! When me an...\n",
       "1      TRUTHFULPOSITIVE  We stayed at the Omni between Christmas and Ne...\n",
       "2     DECEPTIVENEGATIVE  I was REALLY looking forward to a nice relaxin...\n",
       "3      TRUTHFULNEGATIVE  First let me say, I try not to be too critical...\n",
       "4     DECEPTIVENEGATIVE  The Ambassador East Hotel is a terrible place ...\n",
       "...                 ...                                                ...\n",
       "1395   TRUTHFULNEGATIVE  I stayed here for 5 nights last summer. I book...\n",
       "1396   TRUTHFULPOSITIVE  Stayed here for 3 nights for a Bridgestone/Fir...\n",
       "1397   TRUTHFULNEGATIVE  I am staying here now and actually am compelle...\n",
       "1398   TRUTHFULNEGATIVE  We stayed at this hotel with our two teenage d...\n",
       "1399  DECEPTIVEPOSITIVE  The rooms were beautiful! The staff was friend...\n",
       "\n",
       "[1400 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"./datasets/train.txt\"\n",
    "train = pd.read_csv(file_path, sep='\\t', header=None, names=['LABEL', 'REVIEW'])\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REVIEW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My family and I stayed here while we were visi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WARNING! My stay at the Talbott Hotel will go ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I recently stayed at the Hard Rock Hotel in Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O.M.G best hotel ever ! i've stayed at various...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We became an Ambassador member just before spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>The Millennium Knickerbocker Hotel has seen be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>We got a spanking deal at this hotel for $99 a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Just back from a business trip. The Homewood i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>I have just returned from a lovely shopping tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>This hotel had a great location, but you can d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                REVIEW\n",
       "0    My family and I stayed here while we were visi...\n",
       "1    WARNING! My stay at the Talbott Hotel will go ...\n",
       "2    I recently stayed at the Hard Rock Hotel in Ch...\n",
       "3    O.M.G best hotel ever ! i've stayed at various...\n",
       "4    We became an Ambassador member just before spe...\n",
       "..                                                 ...\n",
       "195  The Millennium Knickerbocker Hotel has seen be...\n",
       "196  We got a spanking deal at this hotel for $99 a...\n",
       "197  Just back from a business trip. The Homewood i...\n",
       "198  I have just returned from a lovely shopping tr...\n",
       "199  This hotel had a great location, but you can d...\n",
       "\n",
       "[200 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"./datasets/test_just_reviews.txt\"\n",
    "test = pd.read_csv(file_path, sep='\\t', header=None, names=['REVIEW'])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(train['REVIEW'].values)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(train['REVIEW'].values)\n",
    "X_test = tokenizer.texts_to_sequences(test['REVIEW'].values)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "\tI was REALLY looking forward to a nice relaxing stay at the end of a long vacation, but unfortunately that was not to be had. From the moment we arrived at the Omni, the staff was belligerent and extremely rude. They had lost our reservation and refused to give us the rate we had booked before. If we weren't so tired, we would've gone to a different hotel right then, but hindsight is 20/20. After we FINALLY got checked in after being made to wait needlessly for 45 minutes in the lobby, we decided to go down to the pool, which was tiny and kind of dirty, so we had walked all the way down there in our suits for nothing. The internet access was really slow. I will NEVER stay here again. Save yourself the headache and book somewhere else!\n",
      "Tokenized vector:\n",
      "\t [5, 6, 96, 188, 617, 3, 4, 63, 510, 29, 14, 1, 433, 9, 4, 198, 426, 25, 526, 17, 6, 19, 3, 33, 22, 35, 1, 690, 10, 130, 14, 1, 311, 1, 42, 6, 2, 249, 220, 26, 22, 691, 27, 169, 2, 1080, 3, 328, 52, 1, 282, 10, 22, 149, 151, 53, 10, 639, 40, 525, 10, 2099, 1012, 3, 4, 348, 8, 154, 163, 25, 16, 460, 460, 66, 10, 187, 80, 177, 7, 66, 201, 102, 3, 193, 11, 1048, 162, 7, 1, 112, 10, 251, 3, 101, 116, 3, 1, 226, 72, 6, 572, 2, 531, 9, 331, 40, 10, 22, 377, 38, 1, 155, 116, 31, 7, 27, 3121, 11, 215, 1, 202, 398, 6, 96, 527, 5, 58, 99, 29, 73, 61, 1111, 1313, 1, 2339, 2, 477, 669, 349]\n",
      "Tokens of the first words:\n",
      "\tI: 5\n",
      "\twas: 6\n",
      "\tREALLY: 96\n",
      "\tlooking: 188\n"
     ]
    }
   ],
   "source": [
    "print('Original text:')\n",
    "print('\\t' + train['REVIEW'].values[2])\n",
    "print('Tokenized vector:')\n",
    "print('\\t', X_train[2])\n",
    "\n",
    "print('Tokens of the first words:')\n",
    "for word in ['I', 'was', 'REALLY', 'looking']:\n",
    "    print('\\t{}: {}'.format(word, tokenizer.word_index[word.lower()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1  419    6    4  173    8   36   43    2   15 2336 2664    7   10\n",
      "   20   96  525   40   10  251    3  172    4  600 2665   10 1010  195\n",
      "    3   56   51    1  158   44  363    3 1538   11    5  293    3  172\n",
      "   13  223   18   43    1   41    6   39    2   21    6  656   45    9\n",
      "    1 1895   53   19    1 1895    8 2666  161   47    7   26   22    4\n",
      "   96   63  135  604   18  190  126    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "maxlen = 400\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "\n",
    "print(X_train[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 400, 50)           458900    \n",
      "                                                                 \n",
      " global_max_pooling1d (Glob  (None, 50)                0         \n",
      " alMaxPooling1D)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                510       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 44        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 459454 (1.75 MB)\n",
      "Trainable params: 459454 (1.75 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "embedding_dim = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=vocab_size, \n",
    "                           output_dim=embedding_dim, \n",
    "                           input_length=maxlen))\n",
    "model.add(layers.GlobalMaxPool1D())\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(4, activation='softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "labels = encoder.fit_transform(train['LABEL'].values)\n",
    "labels = to_categorical(labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "126/126 [==============================] - 3s 17ms/step - loss: 1.3745 - accuracy: 0.3087 - val_loss: 1.3565 - val_accuracy: 0.3571\n",
      "Epoch 2/20\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 1.2957 - accuracy: 0.5206 - val_loss: 1.2408 - val_accuracy: 0.5429\n",
      "Epoch 3/20\n",
      "126/126 [==============================] - 2s 16ms/step - loss: 1.1057 - accuracy: 0.6397 - val_loss: 1.0351 - val_accuracy: 0.6714\n",
      "Epoch 4/20\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 0.8548 - accuracy: 0.7627 - val_loss: 0.8494 - val_accuracy: 0.7143\n",
      "Epoch 5/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.6363 - accuracy: 0.8516 - val_loss: 0.7418 - val_accuracy: 0.7714\n",
      "Epoch 6/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.4734 - accuracy: 0.9103 - val_loss: 0.6464 - val_accuracy: 0.8071\n",
      "Epoch 7/20\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 0.3483 - accuracy: 0.9476 - val_loss: 0.5962 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 0.2469 - accuracy: 0.9667 - val_loss: 0.5490 - val_accuracy: 0.8143\n",
      "Epoch 9/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.1746 - accuracy: 0.9817 - val_loss: 0.5718 - val_accuracy: 0.8071\n",
      "Epoch 10/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.1226 - accuracy: 0.9897 - val_loss: 0.5539 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0875 - accuracy: 0.9960 - val_loss: 0.5431 - val_accuracy: 0.8143\n",
      "Epoch 12/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0633 - accuracy: 0.9976 - val_loss: 0.5439 - val_accuracy: 0.8071\n",
      "Epoch 13/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.0465 - accuracy: 0.9984 - val_loss: 0.5651 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.0350 - accuracy: 0.9984 - val_loss: 0.5795 - val_accuracy: 0.8071\n",
      "Epoch 15/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0268 - accuracy: 0.9992 - val_loss: 0.5752 - val_accuracy: 0.8071\n",
      "Epoch 16/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.5831 - val_accuracy: 0.7929\n",
      "Epoch 17/20\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.6029 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.6023 - val_accuracy: 0.8071\n",
      "Epoch 19/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.6179 - val_accuracy: 0.8143\n",
      "Epoch 20/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.6151 - val_accuracy: 0.8000\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/20\n",
      "126/126 [==============================] - 3s 13ms/step - loss: 1.3780 - accuracy: 0.3159 - val_loss: 1.3605 - val_accuracy: 0.3286\n",
      "Epoch 2/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 1.3254 - accuracy: 0.3437 - val_loss: 1.2697 - val_accuracy: 0.4500\n",
      "Epoch 3/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 1.1788 - accuracy: 0.5246 - val_loss: 1.0817 - val_accuracy: 0.5857\n",
      "Epoch 4/20\n",
      "126/126 [==============================] - 1s 12ms/step - loss: 0.9308 - accuracy: 0.7056 - val_loss: 0.8819 - val_accuracy: 0.7214\n",
      "Epoch 5/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.6893 - accuracy: 0.8405 - val_loss: 0.7206 - val_accuracy: 0.7214\n",
      "Epoch 6/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.5020 - accuracy: 0.8881 - val_loss: 0.6443 - val_accuracy: 0.7643\n",
      "Epoch 7/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.3624 - accuracy: 0.9294 - val_loss: 0.5933 - val_accuracy: 0.7786\n",
      "Epoch 8/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.2589 - accuracy: 0.9619 - val_loss: 0.6101 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 0.1885 - accuracy: 0.9754 - val_loss: 0.5773 - val_accuracy: 0.7714\n",
      "Epoch 10/20\n",
      "126/126 [==============================] - 2s 16ms/step - loss: 0.1343 - accuracy: 0.9865 - val_loss: 0.5576 - val_accuracy: 0.7857\n",
      "Epoch 11/20\n",
      "126/126 [==============================] - 2s 17ms/step - loss: 0.0967 - accuracy: 0.9929 - val_loss: 0.5569 - val_accuracy: 0.7929\n",
      "Epoch 12/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0691 - accuracy: 0.9960 - val_loss: 0.5583 - val_accuracy: 0.7786\n",
      "Epoch 13/20\n",
      "126/126 [==============================] - 1s 12ms/step - loss: 0.0498 - accuracy: 0.9984 - val_loss: 0.5648 - val_accuracy: 0.7857\n",
      "Epoch 14/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.0372 - accuracy: 0.9992 - val_loss: 0.5819 - val_accuracy: 0.7786\n",
      "Epoch 15/20\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.5991 - val_accuracy: 0.7786\n",
      "Epoch 16/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.6002 - val_accuracy: 0.7857\n",
      "Epoch 17/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.6184 - val_accuracy: 0.7786\n",
      "Epoch 18/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.6246 - val_accuracy: 0.7786\n",
      "Epoch 19/20\n",
      "126/126 [==============================] - 1s 12ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.6346 - val_accuracy: 0.7786\n",
      "Epoch 20/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.6396 - val_accuracy: 0.7857\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "Epoch 1/20\n",
      "126/126 [==============================] - 3s 15ms/step - loss: 1.3832 - accuracy: 0.2579 - val_loss: 1.3801 - val_accuracy: 0.2500\n",
      "Epoch 2/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 1.3543 - accuracy: 0.3183 - val_loss: 1.3523 - val_accuracy: 0.3643\n",
      "Epoch 3/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 1.2685 - accuracy: 0.5079 - val_loss: 1.2640 - val_accuracy: 0.4714\n",
      "Epoch 4/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 1.0998 - accuracy: 0.6365 - val_loss: 1.1301 - val_accuracy: 0.5214\n",
      "Epoch 5/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.9164 - accuracy: 0.6857 - val_loss: 1.0094 - val_accuracy: 0.5357\n",
      "Epoch 6/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.7342 - accuracy: 0.7889 - val_loss: 0.8986 - val_accuracy: 0.5500\n",
      "Epoch 7/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.5257 - accuracy: 0.9238 - val_loss: 0.8334 - val_accuracy: 0.6071\n",
      "Epoch 8/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.3661 - accuracy: 0.9571 - val_loss: 0.8020 - val_accuracy: 0.6071\n",
      "Epoch 9/20\n",
      "126/126 [==============================] - 1s 12ms/step - loss: 0.2512 - accuracy: 0.9802 - val_loss: 0.7973 - val_accuracy: 0.5929\n",
      "Epoch 10/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.1730 - accuracy: 0.9897 - val_loss: 0.7985 - val_accuracy: 0.6071\n",
      "Epoch 11/20\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 0.1166 - accuracy: 0.9937 - val_loss: 0.8103 - val_accuracy: 0.5786\n",
      "Epoch 12/20\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 0.0769 - accuracy: 0.9984 - val_loss: 0.8209 - val_accuracy: 0.5786\n",
      "Epoch 13/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0504 - accuracy: 0.9984 - val_loss: 0.8435 - val_accuracy: 0.5929\n",
      "Epoch 14/20\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 0.0340 - accuracy: 0.9992 - val_loss: 0.8505 - val_accuracy: 0.5929\n",
      "Epoch 15/20\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.8869 - val_accuracy: 0.6143\n",
      "Epoch 16/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.8893 - val_accuracy: 0.6071\n",
      "Epoch 17/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.9124 - val_accuracy: 0.5857\n",
      "Epoch 18/20\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.9139 - val_accuracy: 0.6071\n",
      "Epoch 19/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.9388 - val_accuracy: 0.6000\n",
      "Epoch 20/20\n",
      "126/126 [==============================] - 1s 11ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.9465 - val_accuracy: 0.6000\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "Epoch 1/20\n",
      "126/126 [==============================] - 3s 14ms/step - loss: 1.3690 - accuracy: 0.3778 - val_loss: 1.3343 - val_accuracy: 0.4214\n",
      "Epoch 2/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 1.2413 - accuracy: 0.5286 - val_loss: 1.1791 - val_accuracy: 0.5143\n",
      "Epoch 3/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 1.0013 - accuracy: 0.6667 - val_loss: 0.9797 - val_accuracy: 0.6286\n",
      "Epoch 4/20\n",
      "126/126 [==============================] - 1s 12ms/step - loss: 0.7688 - accuracy: 0.7675 - val_loss: 0.8367 - val_accuracy: 0.6857\n",
      "Epoch 5/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.5721 - accuracy: 0.8675 - val_loss: 0.7311 - val_accuracy: 0.7429\n",
      "Epoch 6/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.4187 - accuracy: 0.9127 - val_loss: 0.6686 - val_accuracy: 0.7429\n",
      "Epoch 7/20\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 0.2953 - accuracy: 0.9444 - val_loss: 0.6241 - val_accuracy: 0.7429\n",
      "Epoch 8/20\n",
      "126/126 [==============================] - 1s 12ms/step - loss: 0.2053 - accuracy: 0.9714 - val_loss: 0.6030 - val_accuracy: 0.7429\n",
      "Epoch 9/20\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 0.1445 - accuracy: 0.9857 - val_loss: 0.5868 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.1007 - accuracy: 0.9897 - val_loss: 0.5862 - val_accuracy: 0.7643\n",
      "Epoch 11/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.0716 - accuracy: 0.9976 - val_loss: 0.5881 - val_accuracy: 0.7714\n",
      "Epoch 12/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.0519 - accuracy: 0.9992 - val_loss: 0.5882 - val_accuracy: 0.7714\n",
      "Epoch 13/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0385 - accuracy: 0.9992 - val_loss: 0.5938 - val_accuracy: 0.7643\n",
      "Epoch 14/20\n",
      "126/126 [==============================] - 1s 12ms/step - loss: 0.0288 - accuracy: 0.9992 - val_loss: 0.6025 - val_accuracy: 0.7714\n",
      "Epoch 15/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.0223 - accuracy: 0.9992 - val_loss: 0.6107 - val_accuracy: 0.7786\n",
      "Epoch 16/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.6198 - val_accuracy: 0.7786\n",
      "Epoch 17/20\n",
      "126/126 [==============================] - 1s 12ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.6255 - val_accuracy: 0.7714\n",
      "Epoch 18/20\n",
      "126/126 [==============================] - 1s 12ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.6304 - val_accuracy: 0.7643\n",
      "Epoch 19/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.6360 - val_accuracy: 0.7786\n",
      "Epoch 20/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.6395 - val_accuracy: 0.7714\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/20\n",
      "126/126 [==============================] - 3s 14ms/step - loss: 1.3707 - accuracy: 0.2794 - val_loss: 1.3396 - val_accuracy: 0.2643\n",
      "Epoch 2/20\n",
      "126/126 [==============================] - 1s 11ms/step - loss: 1.2854 - accuracy: 0.4690 - val_loss: 1.2332 - val_accuracy: 0.5571\n",
      "Epoch 3/20\n",
      "126/126 [==============================] - 1s 12ms/step - loss: 1.1390 - accuracy: 0.6270 - val_loss: 1.0938 - val_accuracy: 0.6143\n",
      "Epoch 4/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.9395 - accuracy: 0.7746 - val_loss: 0.9174 - val_accuracy: 0.7000\n",
      "Epoch 5/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.6959 - accuracy: 0.8563 - val_loss: 0.7583 - val_accuracy: 0.7214\n",
      "Epoch 6/20\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 0.4904 - accuracy: 0.9048 - val_loss: 0.6479 - val_accuracy: 0.7571\n",
      "Epoch 7/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.3445 - accuracy: 0.9357 - val_loss: 0.5997 - val_accuracy: 0.7643\n",
      "Epoch 8/20\n",
      "126/126 [==============================] - 1s 12ms/step - loss: 0.2459 - accuracy: 0.9659 - val_loss: 0.5474 - val_accuracy: 0.7786\n",
      "Epoch 9/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.1762 - accuracy: 0.9810 - val_loss: 0.5333 - val_accuracy: 0.7714\n",
      "Epoch 10/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.1287 - accuracy: 0.9889 - val_loss: 0.5197 - val_accuracy: 0.7714\n",
      "Epoch 11/20\n",
      "126/126 [==============================] - 1s 12ms/step - loss: 0.0957 - accuracy: 0.9952 - val_loss: 0.5102 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.0721 - accuracy: 0.9960 - val_loss: 0.5019 - val_accuracy: 0.8071\n",
      "Epoch 13/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.0554 - accuracy: 0.9976 - val_loss: 0.5025 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0432 - accuracy: 0.9984 - val_loss: 0.5007 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0341 - accuracy: 0.9992 - val_loss: 0.4941 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.0274 - accuracy: 0.9992 - val_loss: 0.4975 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0221 - accuracy: 0.9992 - val_loss: 0.5050 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.0180 - accuracy: 0.9992 - val_loss: 0.5006 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.0146 - accuracy: 0.9992 - val_loss: 0.5082 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0120 - accuracy: 0.9992 - val_loss: 0.5087 - val_accuracy: 0.8000\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "Epoch 1/20\n",
      "126/126 [==============================] - 3s 14ms/step - loss: 1.3762 - accuracy: 0.3611 - val_loss: 1.3518 - val_accuracy: 0.4429\n",
      "Epoch 2/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 1.2842 - accuracy: 0.5278 - val_loss: 1.2128 - val_accuracy: 0.4929\n",
      "Epoch 3/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 1.0582 - accuracy: 0.6151 - val_loss: 1.0057 - val_accuracy: 0.5714\n",
      "Epoch 4/20\n",
      "126/126 [==============================] - 1s 12ms/step - loss: 0.8255 - accuracy: 0.7032 - val_loss: 0.8752 - val_accuracy: 0.6071\n",
      "Epoch 5/20\n",
      "126/126 [==============================] - 1s 12ms/step - loss: 0.6620 - accuracy: 0.7905 - val_loss: 0.7981 - val_accuracy: 0.6571\n",
      "Epoch 6/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.5317 - accuracy: 0.8563 - val_loss: 0.7443 - val_accuracy: 0.7143\n",
      "Epoch 7/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.4215 - accuracy: 0.9024 - val_loss: 0.6977 - val_accuracy: 0.6929\n",
      "Epoch 8/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.3236 - accuracy: 0.9373 - val_loss: 0.6644 - val_accuracy: 0.7000\n",
      "Epoch 9/20\n",
      "126/126 [==============================] - 1s 11ms/step - loss: 0.2461 - accuracy: 0.9595 - val_loss: 0.6557 - val_accuracy: 0.7071\n",
      "Epoch 10/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.1834 - accuracy: 0.9722 - val_loss: 0.6241 - val_accuracy: 0.7000\n",
      "Epoch 11/20\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 0.1383 - accuracy: 0.9857 - val_loss: 0.6263 - val_accuracy: 0.7000\n",
      "Epoch 12/20\n",
      "126/126 [==============================] - 1s 12ms/step - loss: 0.1026 - accuracy: 0.9889 - val_loss: 0.6161 - val_accuracy: 0.7071\n",
      "Epoch 13/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0772 - accuracy: 0.9944 - val_loss: 0.6150 - val_accuracy: 0.7214\n",
      "Epoch 14/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.0580 - accuracy: 0.9976 - val_loss: 0.6126 - val_accuracy: 0.7214\n",
      "Epoch 15/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0440 - accuracy: 0.9976 - val_loss: 0.6062 - val_accuracy: 0.7286\n",
      "Epoch 16/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0335 - accuracy: 0.9992 - val_loss: 0.6250 - val_accuracy: 0.7357\n",
      "Epoch 17/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0260 - accuracy: 0.9992 - val_loss: 0.6122 - val_accuracy: 0.7286\n",
      "Epoch 18/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.6345 - val_accuracy: 0.7357\n",
      "Epoch 19/20\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.6411 - val_accuracy: 0.7357\n",
      "Epoch 20/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.6490 - val_accuracy: 0.7357\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "Epoch 1/20\n",
      "126/126 [==============================] - 3s 14ms/step - loss: 1.3779 - accuracy: 0.3540 - val_loss: 1.3586 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 1.3219 - accuracy: 0.6071 - val_loss: 1.2709 - val_accuracy: 0.6643\n",
      "Epoch 3/20\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 1.1348 - accuracy: 0.7421 - val_loss: 1.0475 - val_accuracy: 0.6571\n",
      "Epoch 4/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.8067 - accuracy: 0.8167 - val_loss: 0.8318 - val_accuracy: 0.6571\n",
      "Epoch 5/20\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 0.5491 - accuracy: 0.8690 - val_loss: 0.7278 - val_accuracy: 0.6714\n",
      "Epoch 6/20\n",
      "126/126 [==============================] - 2s 16ms/step - loss: 0.3823 - accuracy: 0.9198 - val_loss: 0.6809 - val_accuracy: 0.7071\n",
      "Epoch 7/20\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 0.2684 - accuracy: 0.9484 - val_loss: 0.6944 - val_accuracy: 0.7000\n",
      "Epoch 8/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.1866 - accuracy: 0.9778 - val_loss: 0.6832 - val_accuracy: 0.7000\n",
      "Epoch 9/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.1317 - accuracy: 0.9873 - val_loss: 0.7133 - val_accuracy: 0.7000\n",
      "Epoch 10/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0928 - accuracy: 0.9929 - val_loss: 0.7327 - val_accuracy: 0.7000\n",
      "Epoch 11/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.0673 - accuracy: 0.9960 - val_loss: 0.7514 - val_accuracy: 0.7071\n",
      "Epoch 12/20\n",
      "126/126 [==============================] - 1s 12ms/step - loss: 0.0498 - accuracy: 0.9984 - val_loss: 0.7558 - val_accuracy: 0.7143\n",
      "Epoch 13/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.0378 - accuracy: 0.9992 - val_loss: 0.7818 - val_accuracy: 0.7143\n",
      "Epoch 14/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.0296 - accuracy: 0.9992 - val_loss: 0.7938 - val_accuracy: 0.7143\n",
      "Epoch 15/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.0235 - accuracy: 0.9992 - val_loss: 0.8085 - val_accuracy: 0.7071\n",
      "Epoch 16/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0192 - accuracy: 0.9992 - val_loss: 0.8239 - val_accuracy: 0.7071\n",
      "Epoch 17/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0157 - accuracy: 0.9992 - val_loss: 0.8340 - val_accuracy: 0.7143\n",
      "Epoch 18/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0126 - accuracy: 0.9992 - val_loss: 0.8612 - val_accuracy: 0.7071\n",
      "Epoch 19/20\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 0.0102 - accuracy: 0.9992 - val_loss: 0.8743 - val_accuracy: 0.7000\n",
      "Epoch 20/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.0082 - accuracy: 0.9992 - val_loss: 0.8851 - val_accuracy: 0.7143\n",
      "5/5 [==============================] - 0s 5ms/step\n",
      "Epoch 1/20\n",
      "126/126 [==============================] - 3s 14ms/step - loss: 1.3772 - accuracy: 0.2730 - val_loss: 1.3584 - val_accuracy: 0.3214\n",
      "Epoch 2/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 1.3191 - accuracy: 0.4476 - val_loss: 1.2822 - val_accuracy: 0.3929\n",
      "Epoch 3/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 1.1850 - accuracy: 0.5230 - val_loss: 1.1191 - val_accuracy: 0.5357\n",
      "Epoch 4/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.9655 - accuracy: 0.6690 - val_loss: 0.9267 - val_accuracy: 0.6429\n",
      "Epoch 5/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.7423 - accuracy: 0.8373 - val_loss: 0.7897 - val_accuracy: 0.7143\n",
      "Epoch 6/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.5517 - accuracy: 0.9087 - val_loss: 0.7063 - val_accuracy: 0.7143\n",
      "Epoch 7/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.3947 - accuracy: 0.9444 - val_loss: 0.6404 - val_accuracy: 0.7643\n",
      "Epoch 8/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.2756 - accuracy: 0.9643 - val_loss: 0.6047 - val_accuracy: 0.7929\n",
      "Epoch 9/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.1903 - accuracy: 0.9817 - val_loss: 0.5802 - val_accuracy: 0.7786\n",
      "Epoch 10/20\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 0.1328 - accuracy: 0.9889 - val_loss: 0.5749 - val_accuracy: 0.7714\n",
      "Epoch 11/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0940 - accuracy: 0.9960 - val_loss: 0.5714 - val_accuracy: 0.7786\n",
      "Epoch 12/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0676 - accuracy: 0.9968 - val_loss: 0.5742 - val_accuracy: 0.7714\n",
      "Epoch 13/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0499 - accuracy: 0.9984 - val_loss: 0.5781 - val_accuracy: 0.7786\n",
      "Epoch 14/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0372 - accuracy: 0.9992 - val_loss: 0.5722 - val_accuracy: 0.7786\n",
      "Epoch 15/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0283 - accuracy: 0.9992 - val_loss: 0.5713 - val_accuracy: 0.7714\n",
      "Epoch 16/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0217 - accuracy: 0.9992 - val_loss: 0.5753 - val_accuracy: 0.7714\n",
      "Epoch 17/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.5766 - val_accuracy: 0.7786\n",
      "Epoch 18/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.5818 - val_accuracy: 0.7643\n",
      "Epoch 19/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.5858 - val_accuracy: 0.7571\n",
      "Epoch 20/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.5877 - val_accuracy: 0.7571\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "Epoch 1/20\n",
      "126/126 [==============================] - 3s 14ms/step - loss: 1.3765 - accuracy: 0.3095 - val_loss: 1.3552 - val_accuracy: 0.5429\n",
      "Epoch 2/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 1.3146 - accuracy: 0.6127 - val_loss: 1.2725 - val_accuracy: 0.5357\n",
      "Epoch 3/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 1.1701 - accuracy: 0.6746 - val_loss: 1.1198 - val_accuracy: 0.6214\n",
      "Epoch 4/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.9248 - accuracy: 0.7929 - val_loss: 0.9454 - val_accuracy: 0.6714\n",
      "Epoch 5/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.6705 - accuracy: 0.8603 - val_loss: 0.8096 - val_accuracy: 0.7071\n",
      "Epoch 6/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.4672 - accuracy: 0.9159 - val_loss: 0.7334 - val_accuracy: 0.7143\n",
      "Epoch 7/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.3257 - accuracy: 0.9492 - val_loss: 0.7068 - val_accuracy: 0.7286\n",
      "Epoch 8/20\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 0.2305 - accuracy: 0.9651 - val_loss: 0.6861 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.1644 - accuracy: 0.9794 - val_loss: 0.7041 - val_accuracy: 0.7429\n",
      "Epoch 10/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.1189 - accuracy: 0.9881 - val_loss: 0.6866 - val_accuracy: 0.7429\n",
      "Epoch 11/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0864 - accuracy: 0.9937 - val_loss: 0.7134 - val_accuracy: 0.7643\n",
      "Epoch 12/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0638 - accuracy: 0.9968 - val_loss: 0.7155 - val_accuracy: 0.7786\n",
      "Epoch 13/20\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 0.0473 - accuracy: 1.0000 - val_loss: 0.7352 - val_accuracy: 0.7714\n",
      "Epoch 14/20\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.7411 - val_accuracy: 0.7643\n",
      "Epoch 15/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.7559 - val_accuracy: 0.7571\n",
      "Epoch 16/20\n",
      "126/126 [==============================] - 2s 16ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.7747 - val_accuracy: 0.7571\n",
      "Epoch 17/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.7848 - val_accuracy: 0.7571\n",
      "Epoch 18/20\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.7998 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.8186 - val_accuracy: 0.7571\n",
      "Epoch 20/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.8291 - val_accuracy: 0.7500\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "Epoch 1/20\n",
      "126/126 [==============================] - 3s 18ms/step - loss: 1.3750 - accuracy: 0.3635 - val_loss: 1.3533 - val_accuracy: 0.4929\n",
      "Epoch 2/20\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 1.3059 - accuracy: 0.5944 - val_loss: 1.2486 - val_accuracy: 0.6571\n",
      "Epoch 3/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 1.1127 - accuracy: 0.7683 - val_loss: 0.9918 - val_accuracy: 0.7143\n",
      "Epoch 4/20\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 0.8009 - accuracy: 0.8246 - val_loss: 0.7846 - val_accuracy: 0.7357\n",
      "Epoch 5/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.5581 - accuracy: 0.8706 - val_loss: 0.6530 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.3899 - accuracy: 0.9151 - val_loss: 0.5963 - val_accuracy: 0.7643\n",
      "Epoch 7/20\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 0.2763 - accuracy: 0.9500 - val_loss: 0.5745 - val_accuracy: 0.7786\n",
      "Epoch 8/20\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.1975 - accuracy: 0.9690 - val_loss: 0.5502 - val_accuracy: 0.7857\n",
      "Epoch 9/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.1431 - accuracy: 0.9817 - val_loss: 0.5495 - val_accuracy: 0.7714\n",
      "Epoch 10/20\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 0.1027 - accuracy: 0.9905 - val_loss: 0.5583 - val_accuracy: 0.7643\n",
      "Epoch 11/20\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 0.0746 - accuracy: 0.9929 - val_loss: 0.5546 - val_accuracy: 0.7571\n",
      "Epoch 12/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0554 - accuracy: 0.9968 - val_loss: 0.5767 - val_accuracy: 0.7429\n",
      "Epoch 13/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0414 - accuracy: 0.9992 - val_loss: 0.5882 - val_accuracy: 0.7429\n",
      "Epoch 14/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.5988 - val_accuracy: 0.7429\n",
      "Epoch 15/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.6123 - val_accuracy: 0.7571\n",
      "Epoch 16/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.6296 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.6386 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.6552 - val_accuracy: 0.7643\n",
      "Epoch 19/20\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.6700 - val_accuracy: 0.7643\n",
      "Epoch 20/20\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.6800 - val_accuracy: 0.7500\n",
      "5/5 [==============================] - 0s 6ms/step\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.800000011920929, 0.7857142686843872, 0.6000000238418579, 0.7714285850524902, 0.800000011920929, 0.7357142567634583, 0.7142857313156128, 0.7571428418159485, 0.75, 0.75]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "kf = KFold(n_splits = 10)\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "val_predictions = []\n",
    "val_labels = []\n",
    "for train_index, val_index in kf.split(X_train, labels):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Embedding(input_dim=vocab_size, \n",
    "                            output_dim=embedding_dim, \n",
    "                            input_length=maxlen))\n",
    "    model.add(layers.GlobalMaxPool1D())\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "    model.add(layers.Dense(4, activation='softmax'))\n",
    "    model.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    training_data = X_train[train_index]\n",
    "    training_labels = labels[train_index]\n",
    "    validation_data = X_train[val_index]\n",
    "    validation_labels = labels[val_index]\n",
    "    model.fit(training_data, training_labels, epochs=20, validation_data=(validation_data, validation_labels), verbose=True, batch_size=10)\n",
    "    _, accuracy = model.evaluate(training_data, training_labels, verbose=False)\n",
    "    train_accs.append(accuracy)\n",
    "    _, accuracy = model.evaluate(validation_data, validation_labels, verbose=False)\n",
    "    val_predictions.append(model.predict(validation_data))\n",
    "    val_labels.append(validation_labels)\n",
    "    val_accs.append(accuracy)\n",
    "print(train_accs)\n",
    "print(val_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7464285731315613"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(val_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictions = np.reshape(val_predictions, (1400, 4))\n",
    "val_labels = np.reshape(val_labels, (1400, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 2 ... 2 2 1]\n",
      "[3 3 0 ... 2 2 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2530eeee910>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "predicted = np.argmax(val_predictions, axis=1)\n",
    "print(predicted)\n",
    "actual = np.argmax(val_labels, axis=1)\n",
    "print(actual)\n",
    "confusion_matrix = confusion_matrix(actual, predicted)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = ['DN', 'DP', 'TN', 'TP'])\n",
    "cm_display.plot(cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating test output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "predicted_class_labels = encoder.inverse_transform(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"results/NN.txt\", \"w\")\n",
    "for s in predicted_class_labels:\n",
    "    f.write(s + '\\n')\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
